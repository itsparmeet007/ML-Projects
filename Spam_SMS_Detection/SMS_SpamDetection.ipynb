{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ixAZU7zL6NKQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np #For numerical operations\n",
        "import pandas as pd # For data manuplation and analysis\n",
        "import matplotlib.pyplot as plt # For data Visualisation\n",
        "import seaborn as sns\n",
        "\n",
        "# importing the data File reading and Data processing\n",
        "\n",
        "df = pd.read_csv('emails.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "P86QFguKBQ2l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# here we can see/ Identify our targeted Column [\"Prediction\"]\n",
        "df.columns\n"
      ],
      "metadata": {
        "id": "B_S29fX6CAeK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe().T"
      ],
      "metadata": {
        "id": "86qxpDjLEdl9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Libraries from sklearn and visualization\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report, accuracy_score,confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n"
      ],
      "metadata": {
        "id": "2-mVaASYMKGu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Here we can see No Duplicates\n",
        "df.describe(include = 'object').T"
      ],
      "metadata": {
        "id": "hJvB0ARnM74-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "F2D_dZIINbeg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Here we can No. of Hams and Spams in the data\n",
        "df['Prediction'].value_counts(normalize= True)"
      ],
      "metadata": {
        "id": "HV4IYP9DN9QG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualising the Data\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "counts = df['Prediction'].value_counts(normalize = True)\n",
        "plt.figure(figsize =(10,6))\n",
        "explode = [0.2 ,0]\n",
        "plt.pie(counts.values * 100 ,\n",
        "        labels = [\"Not Spam\",\"Spam\"],\n",
        "        autopct =\"%1.0f%%\",\n",
        "        explode = explode,\n",
        "        colors = ['skyBlue','red'],\n",
        "        startangle=90,\n",
        "        shadow = True)\n",
        "plt.legend()\n",
        "plt.title(\"Prediction\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zSJatEgEQDbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Removing Unnecessary Coloumns\n",
        "df.drop(columns = ['Email No.'])\n",
        "\n",
        "#Why?\n",
        "# Because it contains no information about spam/ham.\n",
        "# It would confuse the model."
      ],
      "metadata": {
        "collapsed": true,
        "id": "Ia2kCG6gOqRh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Divides your dataset into:**\n",
        "\n",
        "80% training ‚Üí used for learning patterns\n",
        "\n",
        "20% testing ‚Üí used to evaluate the model on unseen emails\n",
        "\n",
        "**random_state=26**\n",
        "\n",
        "Ensures you always get the same split every time you run the code\n",
        "\n",
        "Good for reproducibility"
      ],
      "metadata": {
        "id": "CEoDkwDYVAH3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(['Email No.','Prediction'], axis= 1)\n",
        "Y = df['Prediction']\n",
        "x_train , x_test , y_train , y_test = train_test_split(X,Y,test_size = 0.2 , random_state = 26)"
      ],
      "metadata": {
        "id": "bRD7v1bEPp2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L27xzQOXS0vf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**üîç Understanding Logistic Regression Code (Step by Step)**\n",
        "\n",
        "# **1. Import Libraries**\n",
        "**from sklearn.feature_extraction.text import TfidfVectorizer**\n",
        "\n",
        "**from sklearn.linear_model import LogisticRegression**\n",
        "\n",
        "**from sklearn.metrics import classification_report, accuracy_score**\n",
        "\n",
        "**‚úî What this means:**\n",
        "\n",
        "**TfidfVectorizer ‚Üí** Converts email text into numbers (TF-IDF scores).\n",
        "\n",
        "**LogisticRegression ‚Üí** The machine learning algorithm used to classify spam/not spam.\n",
        "\n",
        "**classification_report, accuracy_score ‚Üí** Used to evaluate model performance."
      ],
      "metadata": {
        "id": "O9BwdQzEXaqK"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vvbYmD7QYYCr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TF-IDF = Term Frequency ‚Äì Inverse Document Frequency**\n",
        "\n",
        "Why?\n",
        "\n",
        "Machine learning models cannot understand text directly ‚Üí they need numbers.\n",
        "\n",
        "TF-IDF highlights important words and reduces the weight of common words."
      ],
      "metadata": {
        "id": "nThBKnZuX41V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Train Logistic Regression**\n",
        "**‚úî What this means:**\n",
        "\n",
        "Creates a Logistic Regression model.\n",
        "\n",
        "**max_iter=2000:** increases the number of training cycles so the model converges.\n",
        "\n",
        "**‚úî What the model does:**\n",
        "\n",
        "It finds patterns in text that indicate spam or not spam.\n",
        "\n",
        "**For example:**\n",
        "\n",
        "Words like \"win\", \"prize\", \"free\", \"credit\" ‚Üí likely spam\n",
        "\n",
        "Words like \"meeting\", \"schedule\", \"project\" ‚Üí likely not spam\n",
        "\n",
        "It learns these patterns from your training data."
      ],
      "metadata": {
        "id": "ynX-Cc7vYUXS"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sVzPHipFYUJC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}